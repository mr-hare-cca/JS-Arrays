name: Unit 8.5 Autograding (Prompts + console.log)

on:
  push:
  workflow_dispatch:

jobs:
  autograde:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4

      - name: Setup Node
        id: setup_node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Bootstrap test harness files
        id: write_tests
        shell: bash
        run: |
          mkdir -p tests

          # package.json
          cat > package.json <<'PKG'
          {
            "name": "unit-8-5-prompts-consolelog",
            "version": "1.0.0",
            "private": true,
            "type": "module",
            "scripts": {
              "test": "jest --runInBand --reporters=default"
            },
            "devDependencies": {
              "jest": "^29.7.0",
              "jest-environment-node": "^29.7.0"
            }
          }
          PKG

          # jest.config.js
          cat > jest.config.js <<'JEST'
          export default {
            testEnvironment: "node",
            testMatch: ["**/tests/**/*.test.js"],
            testPathIgnorePatterns: ["/node_modules/", "/__tests__/"]
          };
          JEST

          # tests/script.test.js
          cat > tests/script.test.js <<'TEST'
          import fs from "node:fs";
          import vm from "node:vm";
          import path from "node:path";

          const loadStudent = (answers) => {
            const codePath = path.resolve("script.js");
            const code = fs.readFileSync(codePath, "utf8");

            const logs = [];
            const sandbox = {
              console: { log: (...args) => logs.push(args.map(String).join(" ")) },
              prompt: (() => {
                const queue = [...answers];
                return () => String(queue.shift() ?? "");
              })(),
            };

            vm.createContext(sandbox);
            const script = new vm.Script(code, { filename: "script.js" });
            script.runInContext(sandbox);

            return { logs, code };
          };

          const countOccurrences = (arr, needle) =>
            arr.reduce((acc, line) => acc + (line.trim() === needle ? 1 : 0), 0);

          test("REQUIRED: valid color prints correct action five times; average and evens correct", () => {
            const { logs } = loadStudent(["green", "1", "2", "3", "4", "5"]);
            const goCount = countOccurrences(logs, "Action: Go");
            expect(goCount).toBeGreaterThanOrEqual(5);
            expect(logs.find(l => /Invalid color/i.test(l))).toBeUndefined();

            const avgLine = logs.find(l => /^Average:\\s*-?\\d+(?:\\.\\d+)?$/.test(l.trim()));
            expect(avgLine).toBeDefined();
            const avgValue = Number(avgLine.split(":")[1].trim());
            expect(avgValue).toBeCloseTo(3, 6);

            const evenLine = logs.find(l => /^Even count:\\s*\\d+$/.test(l.trim()));
            expect(evenLine).toBeDefined();
            const evenVal = Number(evenLine.split(":")[1].trim());
            expect(evenVal).toBe(2);
          });

          test("INVALID_COLOR: prints 'Invalid color' and does not print five actions", () => {
            const { logs } = loadStudent(["blue", "10", "20", "30", "40", "50"]);
            const invalid = logs.find(l => /^Invalid color$/i.test(l.trim()));
            expect(invalid).toBeDefined();

            const totalActions = logs.filter(l => /^Action:/.test(l.trim())).length;
            expect(totalActions).toBeLessThan(5);
          });

          test("NO_FUNCTIONS: no function or arrow syntax used", () => {
            const { code } = loadStudent(["red", "1", "2", "3", "4", "5"]);
            expect(/\\bfunction\\b/.test(code) || /=>/.test(code)).toBe(false);
          });
          TEST

      - name: Create lockfile
        id: lockfile
        run: npm install --package-lock-only --ignore-scripts --no-audit --no-fund

      - name: Install
        id: install
        run: npm ci --ignore-scripts --no-audit --no-fund

      - name: Run Jest Tests
        id: run_tests
        run: |
          set -e
          npm test -- --testPathPattern "REQUIRED" --json --outputFile REQUIRED.json
          npm test -- --testPathPattern "INVALID_COLOR" --json --outputFile INVALID_COLOR.json
          npm test -- --testPathPattern "NO_FUNCTIONS" --json --outputFile NO_FUNCTIONS.json

      - name: Prepare reporter env (names must match "T_<ID_UPPERCASE>_RESULTS")
        id: prepare_env
        run: |
          echo "T_REQUIRED_RESULTS=$(cat REQUIRED.json)" >> $GITHUB_ENV
          echo "T_INVALID_COLOR_RESULTS=$(cat INVALID_COLOR.json)" >> $GITHUB_ENV
          echo "T_NO_FUNCTIONS_RESULTS=$(cat NO_FUNCTIONS.json)" >> $GITHUB_ENV

      - name: Report Results
        id: report
        uses: classroom-resources/autograding-grading-reporter@v1
        env:
          T_REQUIRED_RESULTS: ${{ env.T_REQUIRED_RESULTS }}
          T_INVALID_COLOR_RESULTS: ${{ env.T_INVALID_COLOR_RESULTS }}
          T_NO_FUNCTIONS_RESULTS: ${{ env.T_NO_FUNCTIONS_RESULTS }}
        with:
          runners: 'required,invalid_color,no_functions'
