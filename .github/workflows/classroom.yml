name: Unit 8.5 Autograding (Prompts + console.log)

on:
  push:
  workflow_dispatch:

jobs:
  autograde:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install Jest
        run: |
          npm init -y >/dev/null 2>&1 || true
          npm install --save-dev jest@29

      - name: Write jest config
        run: |
          cat > jest.config.cjs <<'EOF'
          module.exports = {
            testEnvironment: 'node',
            testMatch: ['**/__tests__/**/*.test.cjs']
          };
          EOF

      - name: Write tests
        run: |
          mkdir -p __tests__
          cat > __tests__/unit-8-5-arrays.test.cjs <<'EOF'
          const fs = require('fs');
          const path = require('path');

          const scriptPath = path.resolve(process.cwd(), 'script.js');
          const source = fs.existsSync(scriptPath)
            ? fs.readFileSync(scriptPath, 'utf8')
            : '';

          function runWithPrompts(promptValues) {
            if (!fs.existsSync(scriptPath)) {
              throw new Error('script.js not found in repository root.');
            }

            const originalPrompt = global.prompt;
            const originalConsoleLog = console.log;

            let index = 0;
            global.prompt = jest.fn(() => {
              if (index < promptValues.length) {
                return String(promptValues[index++]);
              }
              return '';
            });

            const logs = [];
            console.log = (...args) => {
              logs.push(args.join(' '));
            };

            delete require.cache[scriptPath];
            try {
              require(scriptPath);
            } finally {
              console.log = originalConsoleLog;
              global.prompt = originalPrompt;
            }

            return logs.map(String);
          }

          describe('Unit 8.5 – Arrays (prompts + console.log)', () => {
            test('green action lines', () => {
              const logs = runWithPrompts(['GrEeN', 1, 2, 3, 4, 5]);
              const actions = logs.filter(l => l.startsWith('Action:'));
              expect(actions.length).toBeGreaterThanOrEqual(5);
              expect(actions.slice(0, 5)).toEqual([
                'Action: Go',
                'Action: Go',
                'Action: Go',
                'Action: Go',
                'Action: Go'
              ]);
            });

            test('yellow action lines', () => {
              const logs = runWithPrompts(['YELLOW', 1, 2, 3, 4, 5]);
              const actions = logs.filter(l => l.startsWith('Action:'));
              expect(actions.length).toBeGreaterThanOrEqual(5);
              expect(actions.slice(0, 5)).toEqual([
                'Action: Slow',
                'Action: Slow',
                'Action: Slow',
                'Action: Slow',
                'Action: Slow'
              ]);
            });

            test('red action lines', () => {
              const logs = runWithPrompts(['red', 1, 2, 3, 4, 5]);
              const actions = logs.filter(l => l.startsWith('Action:'));
              expect(actions.length).toBeGreaterThanOrEqual(5);
              expect(actions.slice(0, 5)).toEqual([
                'Action: Stop',
                'Action: Stop',
                'Action: Stop',
                'Action: Stop',
                'Action: Stop'
              ]);
            });

            test('invalid color message', () => {
              const logs = runWithPrompts(['blue', 1, 2, 3, 4, 5]);
              const lower = logs.map(l => l.trim().toLowerCase());
              const invalidLines = lower.filter(l => l === 'invalid color');
              expect(invalidLines.length).toBeGreaterThanOrEqual(1);

              const actionLines = logs.filter(l => l.startsWith('Action:'));
              expect(actionLines.length).toBe(0);
            });

            test('average and even count are correct', () => {
              const logs = runWithPrompts(['green', 2, 4, 6, 8, 10]);
              const avgLine = logs.find(l => l.startsWith('Average:'));
              const evenLine = logs.find(l => l.startsWith('Even count:'));

              expect(avgLine).toBeDefined();
              expect(evenLine).toBeDefined();
              expect(avgLine.trim()).toBe('Average: 6');
              expect(evenLine.trim()).toBe('Even count: 5');
            });

            test('script uses array for numbers', () => {
              expect(source).toBeTruthy();
              const hasBracketArray = /\[[^\]]*\]/.test(source);
              const hasArrayCtor =
                /new\s+Array\s*\(/i.test(source) || /Array\s*\(/.test(source);
              const hasPush = /\.push\s*\(/.test(source);
              const usesIndex =
                /\[[0-4]\]/.test(source) ||
                /\[i\]/.test(source) ||
                /\[index\]/i.test(source);

              expect(hasBracketArray || hasArrayCtor).toBe(true);
              expect(hasPush || usesIndex).toBe(true);
            });
          });
          EOF

      # === Graded steps (sum to 100) ===
      - id: t_green_action
        name: green action lines
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: green action lines
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "green action lines$"
          timeout: 60
          max-score: 15

      - id: t_yellow_action
        name: yellow action lines
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: yellow action lines
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "yellow action lines$"
          timeout: 60
          max-score: 15

      - id: t_red_action
        name: red action lines
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: red action lines
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "red action lines$"
          timeout: 60
          max-score: 15

      - id: t_invalid_color
        name: invalid color message
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: invalid color message
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "invalid color message$"
          timeout: 60
          max-score: 10

      - id: t_avg_even
        name: average and even count are correct
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: average and even count are correct
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "average and even count are correct$"
          timeout: 60
          max-score: 30

      - id: t_array_usage
        name: script uses array for numbers
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: script uses array for numbers
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "script uses array for numbers$"
          timeout: 60
          max-score: 15

      # === Build & publish combined summary (FIXED) ===
      # This step reads the 'result' output from all previous steps
      # and builds the summary with Base64 decoding.
      # This replaces the 'Prepare reporter env' step.
      - name: Build & publish combined summary
        shell: bash
        env:
          T_GREEN_ACTION_RESULTS: ${{ steps.t_green_action.outputs.result }}
          T_YELLOW_ACTION_RESULTS: ${{ steps.t_yellow_action.outputs.result }}
          T_RED_ACTION_RESULTS: ${{ steps.t_red_action.outputs.result }}
          T_INVALID_COLOR_RESULTS: ${{ steps.t_invalid_color.outputs.result }}
          T_AVG_EVEN_RESULTS: ${{ steps.t_avg_even.outputs.result }}
          T_ARRAY_USAGE_RESULTS: ${{ steps.t_array_usage.outputs.result }}
        run: |
          node - <<'NODE'
          const fs = require("fs");

          // These are the canonical test names and their weights
          const weights = {
            "green action lines": 15,
            "yellow action lines": 15,
            "red action lines": 15,
            "invalid color message": 10,
            "average and even count are correct": 30,
            "script uses array for numbers": 15
          };
          const totalPossible = Object.values(weights).reduce((a, b) => a + b, 0);

          // These are the env vars we just defined in the 'env:' block
          const resultKeys = [
            'T_GREEN_ACTION_RESULTS',
            'T_YELLOW_ACTION_RESULTS',
            'T_RED_ACTION_RESULTS',
            'T_INVALID_COLOR_RESULTS',
            'T_AVG_EVEN_RESULTS',
            'T_ARRAY_USAGE_RESULTS'
          ];

          // Parse all the JSON results from the env vars
          const results = [];
          for (const key of resultKeys) {
            try {
              const base64JSON = process.env[key]; // This is Base64 text
              
              // Check if string is present and not empty
              if (base64JSON && base64JSON.length > 0) {
                
                // 1. Decode the Base64 string into a plain UTF-8 string
                const decodedJSON = Buffer.from(base64JSON, 'base64').toString('utf8');
                
                // 2. Parse the plain string as JSON
                results.push(JSON.parse(decodedJSON));

              }
            } catch (e) {
              console.error(`Could not parse result for ${key}:`, e, process.env[key]);
            }
          }

          let totalEarned = 0;
          const lines = ["# Unit 8.5 Autograder Summary"];
          const detailLines = [];
          
          // Iterate over the master list of tests (from 'weights')
          // This ensures all tests are shown, even if a step failed to produce JSON
          for (const name of Object.keys(weights)) {
            const weight = weights[name];
            
            // Find the matching result from our parsed 'results' array
            const res = results.find(r => r['test-name'] === name);
            
            let earned = 0;
            let status = '❌'; // Default to fail

            if (res) {
                // If we found a result, use its data
                earned = res['points-earned'] || 0;
                status = (res.status === 'success') ? '✅' : '❌';
            }
            
            totalEarned += earned;
            // This builds the line: ✅ test name (15/15 pts)
            detailLines.push(`${status} ${name} (${earned}/${weight} pts)`);
          }
          
          // Add the total score line
          lines.push(`**Score: ${totalEarned}/${totalPossible}**`, "");
          // Add all the individual test lines
          lines.push(...detailLines);

          // Write to console and to the job summary
          console.log(lines.join("\n"));
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          if (summaryPath) fs.appendFileSync(summaryPath, lines.join("\n") + "\n");
          NODE

      # Report to Classroom
      - name: Report grades
        uses: classroom-resources/autograding-grading-reporter@v1
        with:
          runners: 't_green_action,t_yellow_action,t_red_action,t_invalid_color,t_avg_even,t_array_usage'
          token: ${{ github.token }}
