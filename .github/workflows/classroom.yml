name: Unit 8.5 Autograding (Prompts + console.log)

on:
  push:
  workflow_dispatch:

jobs:
  autograde:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install Jest
        run: |
          npm init -y >/dev/null 2>&1 || true
          npm install --save-dev jest@29

      - name: Write jest config
        run: |
          cat > jest.config.cjs <<'EOF'
          module.exports = {
            testEnvironment: 'node',
            testMatch: ['**/__tests__/**/*.test.cjs']
          };
          EOF

      - name: Write tests
        run: |
          mkdir -p __tests__
          cat > __tests__/unit-8-5-arrays.test.cjs <<'EOF'
          const fs = require('fs');
          const path = require('path');

          const scriptPath = path.resolve(process.cwd(), 'script.js');
          const source = fs.existsSync(scriptPath)
            ? fs.readFileSync(scriptPath, 'utf8')
            : '';

          function runWithPrompts(promptValues) {
            if (!fs.existsSync(scriptPath)) {
              throw new Error('script.js not found in repository root.');
            }

            const originalPrompt = global.prompt;
            const originalConsoleLog = console.log;

            let index = 0;
            global.prompt = jest.fn(() => {
              if (index < promptValues.length) {
                return String(promptValues[index++]);
              }
              return '';
            });

            const logs = [];
            console.log = (...args) => {
              logs.push(args.join(' '));
            };

            delete require.cache[scriptPath];
            try {
              require(scriptPath);
            } finally {
              console.log = originalConsoleLog;
              global.prompt = originalPrompt;
            }

            return logs.map(String);
          }

          describe('Unit 8.5 – Arrays (prompts + console.log)', () => {
            test('green action lines', () => {
              const logs = runWithPrompts(['GrEeN', 1, 2, 3, 4, 5]);
              const actions = logs.filter(l => l.startsWith('Action:'));
              expect(actions.length).toBeGreaterThanOrEqual(5);
              expect(actions.slice(0, 5)).toEqual([
                'Action: Go',
                'Action: Go',
                'Action: Go',
                'Action: Go',
                'Action: Go'
              ]);
            });

            test('yellow action lines', () => {
              const logs = runWithPrompts(['YELLOW', 1, 2, 3, 4, 5]);
              const actions = logs.filter(l => l.startsWith('Action:'));
              expect(actions.length).toBeGreaterThanOrEqual(5);
              expect(actions.slice(0, 5)).toEqual([
                'Action: Slow',
                'Action: Slow',
                'Action: Slow',
                'Action: Slow',
                'Action: Slow'
              ]);
            });

            test('red action lines', () => {
              const logs = runWithPrompts(['red', 1, 2, 3, 4, 5]);
              const actions = logs.filter(l => l.startsWith('Action:'));
              expect(actions.length).toBeGreaterThanOrEqual(5);
              expect(actions.slice(0, 5)).toEqual([
                'Action: Stop',
                'Action: Stop',
                'Action: Stop',
                'Action: Stop',
                'Action: Stop'
              ]);
            });

            test('invalid color message', () => {
              const logs = runWithPrompts(['blue', 1, 2, 3, 4, 5]);
              const lower = logs.map(l => l.trim().toLowerCase());
              const invalidLines = lower.filter(l => l === 'invalid color');
              expect(invalidLines.length).toBeGreaterThanOrEqual(1);

              const actionLines = logs.filter(l => l.startsWith('Action:'));
              expect(actionLines.length).toBe(0);
            });

            test('average and even count are correct', () => {
              const logs = runWithPrompts(['green', 2, 4, 6, 8, 10]);
              const avgLine = logs.find(l => l.startsWith('Average:'));
              const evenLine = logs.find(l => l.startsWith('Even count:'));

              expect(avgLine).toBeDefined();
              expect(evenLine).toBeDefined();
              expect(avgLine.trim()).toBe('Average: 6');
              expect(evenLine.trim()).toBe('Even count: 5');
            });

            test('script uses array for numbers', () => {
              expect(source).toBeTruthy();
              const hasBracketArray = /\[[^\]]*\]/.test(source);
              const hasArrayCtor =
                /new\s+Array\s*\(/i.test(source) || /Array\s*\(/.test(source);
              const hasPush = /\.push\s*\(/.test(source);
              const usesIndex =
                /\[[0-4]\]/.test(source) ||
                /\[i\]/.test(source) ||
                /\[index\]/i.test(source);

              expect(hasBracketArray || hasArrayCtor).toBe(true);
              expect(hasPush || usesIndex).toBe(true);
            });
          });
          EOF

      # === Graded steps (sum to 100) ===
      - id: t_green_action
        name: green action lines
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: green action lines
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "green action lines$"
          timeout: 60
          max-score: 15

      - id: t_yellow_action
        name: yellow action lines
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: yellow action lines
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "yellow action lines$"
          timeout: 60
          max-score: 15

      - id: t_red_action
        name: red action lines
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: red action lines
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "red action lines$"
          timeout: 60
          max-score: 15

      - id: t_invalid_color
        name: invalid color message
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: invalid color message
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "invalid color message$"
          timeout: 60
          max-score: 10

      - id: t_avg_even
        name: average and even count are correct
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: average and even count are correct
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "average and even count are correct$"
          timeout: 60
          max-score: 30

      - id: t_array_usage
        name: script uses array for numbers
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: script uses array for numbers
          setup-command: echo "ready"
          command: npx jest --runInBand --testNamePattern "script uses array for numbers$"
          timeout: 60
          max-score: 15

      # Build & publish combined summary (console + Summary tab)
      - name: Build & publish combined summary
        shell: bash
        run: |
          npx jest --runInBand --json --outputFile=jest-summary.json || true
          node - <<'NODE'
          const fs = require("fs");
          let jr = {};
          try { jr = JSON.parse(fs.readFileSync("jest-summary.json","utf8")); } catch {}
          const assertions = (jr.testResults||[]).flatMap(t => t.assertionResults || []);

          const wanted = [
            "green action lines",
            "yellow action lines",
            "red action lines",
            "invalid color message",
            "average and even count are correct",
            "script uses array for numbers"
          ];

          const weights = {
            "green action lines": 15,
            "yellow action lines": 15,
            "red action lines": 15,
            "invalid color message": 10,
            "average and even count are correct": 30,
            "script uses array for numbers": 15
          };

          const status = {};
          for (const name of wanted) {
            const a = assertions.find(x => x.title === name);
            status[name] = !!a && a.status === "passed";
          }

          const earned = Object.entries(weights).reduce(
            (sum, [k, pts]) => sum + (status[k] ? pts : 0),
            0
          );
          const total = Object.values(weights).reduce((a,b)=>a+b,0);

          const lines = [];
          lines.push("# Unit 8.5 Autograder Summary");
          lines.push(`**Score: ${earned}/${total}**`, "");
          for (const name of wanted) {
            const weight = weights[name] || 0;
            lines.push(`${status[name] ? "✅" : "❌"} ${name} (${weight} pts)`);
          }
          console.log(lines.join("\n"));

          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          if (summaryPath) fs.appendFileSync(summaryPath, lines.join("\n") + "\n");
          NODE

      # Prepare reporter env
      - name: Prepare reporter env
        id: prepEnv
        shell: bash
        run: |
          echo "T_GREEN_ACTION_RESULTS=${{ steps.t_green_action.outputs.result }}"       >> "$GITHUB_ENV"
          echo "T_YELLOW_ACTION_RESULTS=${{ steps.t_yellow_action.outputs.result }}"     >> "$GITHUB_ENV"
          echo "T_RED_ACTION_RESULTS=${{ steps.t_red_action.outputs.result }}"           >> "$GITHUB_ENV"
          echo "T_INVALID_COLOR_RESULTS=${{ steps.t_invalid_color.outputs.result }}"     >> "$GITHUB_ENV"
          echo "T_AVG_EVEN_RESULTS=${{ steps.t_avg_even.outputs.result }}"               >> "$GITHUB_ENV"
          echo "T_ARRAY_USAGE_RESULTS=${{ steps.t_array_usage.outputs.result }}"         >> "$GITHUB_ENV"

      # Report to Classroom
      - name: Report grades
        uses: classroom-resources/autograding-grading-reporter@v1
        with:
          runners: 't_green_action,t_yellow_action,t_red_action,t_invalid_color,t_avg_even,t_array_usage'
          token: ${{ github.token }}
